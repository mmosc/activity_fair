{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "892c7495-49e5-4cac-a4d6-12cbbfd70751",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "    a. Accuracy: NDCG@10 for all \"faithful\" users, and for \"core\" users\n",
    "    b. Coverage NDCG@10 for all \"faithful\" users\n",
    "    c. Novelty, with Popularity of items defined on the full training set\n",
    "    d. Item fairness: Interaction Segmentation as defined in 3.c (percentiles) on the full training set, according to a [60, 30, 10] percentile split. Keyword: [Short Head, Mid Tail, Long Tail].\n",
    "    e. User fairness: Activity Segmentation as defined in 3.b (percentiles), according to a [60, 30, 10] percentage of users split. Keyword: [active,  semi-active, inactive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fdaf93-6127-4657-affe-e251a8bd3328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.quick_start import load_data_and_model\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from recbole.utils.case_study import full_sort_topk\n",
    "import os\n",
    "from recsyslearn.accuracy.metrics import NDCG\n",
    "from recsyslearn.dataset.utils import find_relevant_items\n",
    "from recsyslearn.beyond_accuracy.metrics import Coverage\n",
    "from recsyslearn.beyond_accuracy.metrics import Novelty\n",
    "from recsyslearn.fairness.metrics import KullbackLeibler\n",
    "from recsyslearn.dataset.segmentations import PopularityPercentage\n",
    "from recsyslearn.dataset.segmentations import InteractionSegmentation\n",
    "# from recsyslearn.dataset.segmentations import ActivitySegmentation\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b083f26d-cf59-4ce2-8e7f-bfbd44136e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsyslearn.fairness.metrics import FairnessMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d6c3b5-4030-41ba-975c-dadef3423d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recsyslearn.fairness.utils import eff_matrix\n",
    "from recsyslearn.utils import check_columns_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859fc072-ce82-401c-9c38-b90f22da97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivitySegmentation(Segmentation):\n",
    "\n",
    "    \"\"\"\n",
    "    Segmentation of users based on their number of interaction.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def segment(cls, dataset: pd.DataFrame, proportions=None, min_interaction: int = 0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Segmentation of users based on their interactions with different items.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset : pd.DataFrame\n",
    "            The complete dataset.\n",
    "        proportions : list, default [0.8, 0.2]\n",
    "            The proportion of interactions wanted for every group.\n",
    "        min_interaction : int, default 0\n",
    "            The minimum number of interaction allowed per user. Users below this threshold will be removed.\n",
    "        Raises\n",
    "        ------\n",
    "        SegmentationNotSupportedException\n",
    "            If len(proportion) not in (1, 2, 3).\n",
    "        WrongProportionsException\n",
    "            If sum(proportion) is not 1, which means it doesn't cover all the items/users.\n",
    "        Return\n",
    "        ------\n",
    "        DataFrame with users and belonging group.\n",
    "        \"\"\"\n",
    "\n",
    "        if proportions is None:\n",
    "            proportions = [0.1, 0.9]\n",
    "\n",
    "        if len(proportions) == 1:\n",
    "            return dataset\n",
    "\n",
    "        if len(proportions) not in (2, 3):\n",
    "            raise SegmentationNotSupportedException(\n",
    "                \"Number of supported group is between 1 and 3.\")\n",
    "\n",
    "        if np.sum(proportions * 10) / 10 != 1:\n",
    "            raise WrongProportionsException()\n",
    "\n",
    "        user_groups = dataset.groupby('user').size().reset_index(name='count')\n",
    "        user_groups = user_groups.loc[user_groups['count']\n",
    "                                      >= min_interaction, :]\n",
    "\n",
    "        user_groups.loc[:, 'count'] = user_groups.loc[:, 'count'].apply(\n",
    "            lambda x: x + np.random.choice(list(range(10))))\n",
    "        user_groups = user_groups.sort_values('count', ascending=False)\n",
    "        user_groups.loc[:, 'count'] = np.arange(user_groups.shape[0]) + 1\n",
    "        first_thr = np.rint(proportions[0] * user_groups.shape[0])\n",
    "        second_thr = np.rint(proportions[1] * user_groups.shape[0]) + first_thr\n",
    "        first_thr = first_thr if first_thr > 0 else 1\n",
    "        first_group = user_groups.loc[user_groups['count'] <=\n",
    "            first_thr, 'user']\n",
    "        second_group = user_groups.loc[user_groups['count'].lt(\n",
    "            second_thr), 'user']\n",
    "\n",
    "        conditions = [user_groups['user'].isin(\n",
    "            first_group), user_groups['user'].isin(second_group)]\n",
    "        choices = (1, 2)\n",
    "        default = len(proportions)\n",
    "        user_groups.loc[:, 'group'] = np.select(\n",
    "            conditions, choices, default=default)\n",
    "\n",
    "        return user_groups[['user', 'group']].astype({'user': str, 'group': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c74357-8e50-4121-bc15-979742fafd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserLevelEntropy(FairnessMetric):\n",
    "\n",
    "    \"\"\"\n",
    "    Entropy evaluator for recommender systems, returning an entropy value for each user.\n",
    "    \"\"\"\n",
    "\n",
    "    def evaluate(self, top_n: pd.DataFrame, rel_matrix: pd.DataFrame = None) -> float:\n",
    "        \"\"\"\n",
    "        Compute the entropy of a model by using its recommendation list.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        top_n : pd.DataFrame\n",
    "            Top N recommendations' lists for every user with items or users already segmented.\n",
    "\n",
    "        rel_matrix : pd.DataFrame, default None\n",
    "            Relevant items for users. It could be, for example, the items with a rating >= threshold.\n",
    "\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        ColumnsNotExistException\n",
    "            If top_n not in the form ('user', 'item', 'rank', 'group').\n",
    "\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        The computed entropy.\n",
    "        \"\"\"\n",
    "\n",
    "        check_columns_exist(top_n, ['user', 'item', 'rank', 'group'])\n",
    "\n",
    "        top_n = eff_matrix(\n",
    "            top_n, rel_matrix) if rel_matrix is not None else top_n\n",
    "\n",
    "        top_n = top_n.groupby(['user', 'group'], as_index=False).sum()\n",
    "        top_n['sum'] = [top_n[top_n.user == user]['rank'].sum() for user in top_n.user.values]\n",
    "\n",
    "        top_n['rank'] = top_n['rank'] / top_n['sum']\n",
    "        top_n['rank'] = - top_n['rank'] * np.log2(top_n['rank'])\n",
    "\n",
    "        top_n = top_n[['user', 'rank']].groupby(['user'], as_index=False).sum()\n",
    "\n",
    "        return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27516af8-28ad-4f0c-91bd-aebd7230f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1340ea6b-1b5d-4d54-8d7d-1af1e4efc9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/pandas/core/arraylike.py:397: RuntimeWarning: divide by zero encountered in log2\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "harmful_list = [0.00, 0.01, 0.05, 0.10]\n",
    "ITEM_TARGET = [0.6, 0.3, 0.1]\n",
    "ITEM_TARGET_DF = pd.DataFrame()\n",
    "ITEM_TARGET_DF['group'] = list(range(1, len(ITEM_TARGET) + 1))\n",
    "ITEM_TARGET_DF['target_representation'] = ITEM_TARGET\n",
    "\n",
    "\n",
    "USER_TARGET = [0.6, 0.3, 0.1]\n",
    "USER_TARGET_DF = pd.DataFrame()\n",
    "USER_TARGET_DF['group'] = list(range(1, len(USER_TARGET) + 1))\n",
    "USER_TARGET_DF['target_representation'] = USER_TARGET\n",
    "\n",
    "\n",
    "# DATASET_LIST = ['ml-100k']\n",
    "DATASET_LIST = ['ml-100k', 'lastfm']\n",
    "BASE_FOLDER = '/home/marta/jku/activity_fair/'\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=[\n",
    "    'model',\n",
    "    'harm',\n",
    "    'dataset',\n",
    "    'NDCG@10_full',\n",
    "    'NDCG@10_core',\n",
    "    'coverage',\n",
    "    'novelty',\n",
    "    'kl_item',\n",
    "    'kl_user',\n",
    "])\n",
    "for DATASET in DATASET_LIST:\n",
    "    FULL_DATASETS_FOLDER = BASE_FOLDER + f'datasets/full_datasets/{DATASET}/'\n",
    "    BINARIZED_CORE_INTERACTION_FILE = FULL_DATASETS_FOLDER + f'{DATASET}_bin_core.inter'\n",
    "    binarized = pd.read_csv(BINARIZED_CORE_INTERACTION_FILE, sep='\\t')\n",
    "    # print(binarized.info())\n",
    "    binarized.columns = ['user', 'item']\n",
    "    \n",
    "\n",
    "    ITEM_GROUPS = InteractionSegmentation().segment(\n",
    "        binarized, \n",
    "        proportions=ITEM_TARGET,\n",
    "    )\n",
    "    ITEM_GROUPS = ITEM_GROUPS.astype({\n",
    "        'item': int,\n",
    "    })\n",
    "    USER_GROUPS = ActivitySegmentation().segment(\n",
    "        binarized, \n",
    "        proportions=USER_TARGET,\n",
    "    )\n",
    "    USER_GROUPS = USER_GROUPS.astype({\n",
    "        'user': str,\n",
    "    })\n",
    "    \n",
    "    ### \n",
    "    harmful = 0.10\n",
    "    DS_STRING = f'{DATASET}_harm{str(int(100*harmful)).zfill(2)}'\n",
    "    TEST_DATA_FILE = f'{BASE_FOLDER}/test/{DS_STRING}.tsv'\n",
    "    TEST_DATASET_CORE = pd.read_csv(TEST_DATA_FILE, sep='\\t')\n",
    "    POS_ITEMS_TEST_CORE = find_relevant_items(TEST_DATASET_CORE).astype({\n",
    "        'user': str,\n",
    "    })\n",
    "    test_users_core = POS_ITEMS_TEST_CORE.user.values\n",
    "\n",
    "    for harmful in harmful_list:\n",
    "    \n",
    "        DS_STRING = f'{DATASET}_harm{str(int(100*harmful)).zfill(2)}'\n",
    "        \n",
    "        row_dict = {}\n",
    "        row_dict['model'] = 'bpr'\n",
    "        row_dict['dataset'] = DATASET\n",
    "        row_dict['harm'] = harmful\n",
    "        \n",
    "        \n",
    "        MODEL_FOLDER = f'{BASE_FOLDER}saved/{DS_STRING}/'\n",
    "        top_k_df = pd.read_csv(f'{MODEL_FOLDER}/best_model.tsv', sep='\\t')\n",
    "        #print(top_k_df.info())\n",
    "        top_k_df = top_k_df.astype({\n",
    "            'user': str,\n",
    "            'item': int,\n",
    "        })\n",
    "        \n",
    "        TEST_DATA_FILE = f'{BASE_FOLDER}/test/{DS_STRING}.tsv'\n",
    "        TEST_DATASET_RANK = pd.read_csv(TEST_DATA_FILE, sep='\\t')\n",
    "        POS_ITEMS_TEST = find_relevant_items(TEST_DATASET_RANK).astype({\n",
    "            'user': str,\n",
    "        })\n",
    "        test_users = top_k_df.user.values\n",
    "\n",
    "        POS_ITEMS_TEST = POS_ITEMS_TEST.astype({\n",
    "            'user': str,\n",
    "        })\n",
    "        POS_ITEMS_TEST = POS_ITEMS_TEST[POS_ITEMS_TEST.user.isin(test_users)]\n",
    "        \n",
    "        # NDCG Full\n",
    "        ndcg = NDCG().evaluate(\n",
    "            top_n=top_k_df,\n",
    "            pos_items=POS_ITEMS_TEST,\n",
    "            ats=(10,),\n",
    "        ).mean()\n",
    "        # print(top_k_df.info())\n",
    "        # print(POS_ITEMS_TEST.info())\n",
    "        row_dict['NDCG@10_full'] = ndcg['NDCG@10']\n",
    "        \n",
    "        \n",
    "        # NDCG Core\n",
    "        POS_ITEMS_TEST_CORE = POS_ITEMS_TEST[POS_ITEMS_TEST.user.isin(test_users_core)]\n",
    "        top_k_core_df = top_k_df[top_k_df.user.isin(test_users_core)]\n",
    "        \n",
    "        ndcg = NDCG().evaluate(\n",
    "            top_n=top_k_core_df,\n",
    "            pos_items=POS_ITEMS_TEST_CORE,\n",
    "            ats=(10,),\n",
    "        ).mean()\n",
    "        # print(top_k_df.info())\n",
    "        # print(POS_ITEMS_TEST.info())\n",
    "        row_dict['NDCG@10_core'] = ndcg['NDCG@10']\n",
    "        \n",
    "        \n",
    "        # COVERAGE\n",
    "        # print(binarized.info())\n",
    "        items = list(binarized['item'].unique())\n",
    "        coverage = Coverage.evaluate(\n",
    "            top_n=top_k_df,\n",
    "            items=items,\n",
    "        )\n",
    "        row_dict['coverage'] = coverage\n",
    "        \n",
    "        # NOVELTY\n",
    "\n",
    "        ITEM_POPULARITY = PopularityPercentage().segment(binarized, group='item')\n",
    "        popularity_top_k = top_k_df.merge(ITEM_POPULARITY, how='inner', left_on='item', right_on='item')\n",
    "        novelty = Novelty.evaluate(\n",
    "            top_n=popularity_top_k,\n",
    "            popularity_definition='percentage',\n",
    "        )\n",
    "        row_dict['novelty'] = novelty\n",
    "\n",
    "        # Item KL\n",
    "        item_segmented_top_k = top_k_df.merge(ITEM_GROUPS, how='inner', left_on='item', right_on='item')\n",
    "        item_segmented_top_k['rank'] = item_segmented_top_k['rank'].astype(float)\n",
    "        item_segmented_top_k['group'] = item_segmented_top_k['group'].astype(int)\n",
    "\n",
    "        item_kl = KullbackLeibler().evaluate(\n",
    "            top_n=item_segmented_top_k,\n",
    "            target_representation=ITEM_TARGET_DF,\n",
    "        )\n",
    "        row_dict['kl_item'] = item_kl\n",
    "        # User KL\n",
    "        user_segmented_top_k = top_k_df.merge(USER_GROUPS, how='inner', left_on='user', right_on='user')\n",
    "        user_segmented_top_k['rank'] = user_segmented_top_k['rank'].astype(float)\n",
    "        user_segmented_top_k['group'] = user_segmented_top_k['group'].astype(int)\n",
    "\n",
    "        user_segmented_testset = top_k_df.merge(USER_GROUPS, how='inner', left_on='user', right_on='user')\n",
    "        user_segmented_top_k['rank'] = user_segmented_top_k['rank'].astype(float)\n",
    "        user_segmented_top_k['group'] = user_segmented_top_k['group'].astype(int)\n",
    "\n",
    "        user_segmented_rel_matrix = TEST_DATASET_RANK.astype({'user': object}).merge(USER_GROUPS, how='inner', left_on='user',\n",
    "                                                              right_on='user')\n",
    "\n",
    "        user_segmented_rel_matrix['group'] = user_segmented_rel_matrix['group'].astype(int)\n",
    "        \n",
    "        user_kl = KullbackLeibler().evaluate(\n",
    "            top_n=user_segmented_top_k,\n",
    "            target_representation=USER_TARGET_DF,\n",
    "            rel_matrix=user_segmented_rel_matrix,\n",
    "        )\n",
    "        row_dict['kl_user'] = user_kl\n",
    "\n",
    "        metrics_df.loc[len(metrics_df)] = row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693ecc4a-dd0f-403c-8b8a-4f3c4285f5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>harm</th>\n",
       "      <th>dataset</th>\n",
       "      <th>NDCG@10_full</th>\n",
       "      <th>NDCG@10_core</th>\n",
       "      <th>coverage</th>\n",
       "      <th>novelty</th>\n",
       "      <th>kl_item</th>\n",
       "      <th>kl_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ml-100k</td>\n",
       "      <td>0.308688</td>\n",
       "      <td>0.319263</td>\n",
       "      <td>0.530496</td>\n",
       "      <td>8.951056</td>\n",
       "      <td>0.196501</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>ml-100k</td>\n",
       "      <td>0.300252</td>\n",
       "      <td>0.306165</td>\n",
       "      <td>0.472681</td>\n",
       "      <td>8.891897</td>\n",
       "      <td>0.263559</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.05</td>\n",
       "      <td>ml-100k</td>\n",
       "      <td>0.295771</td>\n",
       "      <td>0.305701</td>\n",
       "      <td>0.479034</td>\n",
       "      <td>8.905236</td>\n",
       "      <td>0.240036</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.10</td>\n",
       "      <td>ml-100k</td>\n",
       "      <td>0.311504</td>\n",
       "      <td>0.311504</td>\n",
       "      <td>0.517154</td>\n",
       "      <td>8.944851</td>\n",
       "      <td>0.219525</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.00</td>\n",
       "      <td>lastfm</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>0.177332</td>\n",
       "      <td>0.169202</td>\n",
       "      <td>9.488832</td>\n",
       "      <td>0.526923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.01</td>\n",
       "      <td>lastfm</td>\n",
       "      <td>0.174362</td>\n",
       "      <td>0.171891</td>\n",
       "      <td>0.170803</td>\n",
       "      <td>9.494341</td>\n",
       "      <td>0.528596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.05</td>\n",
       "      <td>lastfm</td>\n",
       "      <td>0.180102</td>\n",
       "      <td>0.179386</td>\n",
       "      <td>0.167486</td>\n",
       "      <td>9.864206</td>\n",
       "      <td>0.473751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bpr</td>\n",
       "      <td>0.10</td>\n",
       "      <td>lastfm</td>\n",
       "      <td>0.178875</td>\n",
       "      <td>0.178875</td>\n",
       "      <td>0.156793</td>\n",
       "      <td>9.663178</td>\n",
       "      <td>0.508998</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  harm  dataset  NDCG@10_full  NDCG@10_core  coverage   novelty  \\\n",
       "0   bpr  0.00  ml-100k      0.308688      0.319263  0.530496  8.951056   \n",
       "1   bpr  0.01  ml-100k      0.300252      0.306165  0.472681  8.891897   \n",
       "2   bpr  0.05  ml-100k      0.295771      0.305701  0.479034  8.905236   \n",
       "3   bpr  0.10  ml-100k      0.311504      0.311504  0.517154  8.944851   \n",
       "4   bpr  0.00   lastfm      0.176455      0.177332  0.169202  9.488832   \n",
       "5   bpr  0.01   lastfm      0.174362      0.171891  0.170803  9.494341   \n",
       "6   bpr  0.05   lastfm      0.180102      0.179386  0.167486  9.864206   \n",
       "7   bpr  0.10   lastfm      0.178875      0.178875  0.156793  9.663178   \n",
       "\n",
       "    kl_item  kl_user  \n",
       "0  0.196501      0.0  \n",
       "1  0.263559      0.0  \n",
       "2  0.240036      0.0  \n",
       "3  0.219525      0.0  \n",
       "4  0.526923      0.0  \n",
       "5  0.528596      0.0  \n",
       "6  0.473751      0.0  \n",
       "7  0.508998      0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.reset_option(\"display.precision\")\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c9945-96ce-4d58-92c0-1b4b4514427f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "recbole"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

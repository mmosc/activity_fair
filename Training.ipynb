{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7d1b80-d3ec-4cc6-b514-6ce8428b8a6c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55aec402-1fd2-498c-a9f1-5121f8348c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/marta/jku/activity_fair\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "274157a4-5a83-427b-bda0-00a8c31a81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "harmful_list = [0.00, 0.01, 0.05, 0.10]\n",
    "# DATASET = 'ml-100k'\n",
    "# DATASET = 'amazon_digital_music'\n",
    "DATASET = 'lastfm'\n",
    "MODEL_LIST = ['BPR', 'ItemKNN', 'MultiVAE']\n",
    "\n",
    "MODEL = 'MultiVAE'\n",
    "\n",
    "data_path_dict = {\n",
    "    f'{DATASET}_harm{str(int(100*harmful)).zfill(2)}':\n",
    "    '/home/marta/jku/activity_fair/datasets/filtered_datasets/' for harmful in harmful_list\n",
    "}\n",
    "\n",
    "config_dict = {\n",
    "    'BPR': 'bpr_config',\n",
    "    'ItemKNN': 'iknn_config',\n",
    "    'MultiVAE': 'vae_config',\n",
    "}\n",
    "\n",
    "params_dict = {\n",
    "    'BPR': 'bpr_params',\n",
    "    'ItemKNN': 'iknn_params',\n",
    "    'MultiVAE': 'vae_params',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f69cac-ede2-4dd2-8f62-1e53db4e440b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ml-100k_harm00': '/home/marta/jku/activity_fair/datasets/filtered_datasets/',\n",
       " 'ml-100k_harm01': '/home/marta/jku/activity_fair/datasets/filtered_datasets/',\n",
       " 'ml-100k_harm05': '/home/marta/jku/activity_fair/datasets/filtered_datasets/',\n",
       " 'ml-100k_harm10': '/home/marta/jku/activity_fair/datasets/filtered_datasets/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe25eb-12d9-4749-8776-7c574b5f08f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "BASE_FOLDER = '/home/marta/jku/activity_fair/'\n",
    "\n",
    "CONFIG_FILE = config_dict[MODEL]\n",
    "PARAMS_FILE = params_dict[MODEL]\n",
    "\n",
    "for data_version, data_path in data_path_dict.items():\n",
    "    command = f\"python {BASE_FOLDER}/run_hyper.py \\\n",
    "    --model={MODEL} \\\n",
    "    --data_path={data_path} \\\n",
    "    --dataset={data_version} \\\n",
    "    --config_files={BASE_FOLDER}/config/{CONFIG_FILE}.yaml \\\n",
    "    --params_file={BASE_FOLDER}/config/{PARAMS_FILE}.yaml \\\n",
    "    --checkpoint_dir={BASE_FOLDER}saved/{data_version}\\\n",
    "    --tool=Hyperopt\"\n",
    "    !eval {command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5c2ee9-5cd8-4d8c-9a18-b15c9e7ca8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 18:40    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 18:40    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:40    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:40    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:40    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:41    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-40-52.pth\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:41    WARNING  Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:41    WARNING    File \"/home/marta/jku/activity_fair//run_hyper.py\", line 127, in <module>\n",
      "    hyperopt_tune(args)\n",
      "  File \"/home/marta/jku/activity_fair//run_hyper.py\", line 39, in hyperopt_tune\n",
      "    hp.run()\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/quick_start/quick_start.py\", line 153, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\u001b[0m\n",
      "\n",
      "current best valid score: 0.2772                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2772)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3568)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  2%|▍                    | 1/48 [00:46<36:29, 46.58s/trial, best loss: -0.2772]15 Feb 18:41    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  2%|▍                    | 1/48 [00:46<36:29, 46.58s/trial, best loss: -0.2772]15 Feb 18:41    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:41    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:41    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:41    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-41-38.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  4%|▉                    | 2/48 [01:21<30:28, 39.75s/trial, best loss: -0.2772]15 Feb 18:42    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  4%|▉                    | 2/48 [01:21<30:28, 39.75s/trial, best loss: -0.2772]15 Feb 18:42    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:42    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-42-13.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      "  6%|█▎                   | 3/48 [01:44<24:04, 32.10s/trial, best loss: -0.2772]15 Feb 18:42    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  6%|█▎                   | 3/48 [01:44<24:04, 32.10s/trial, best loss: -0.2772]15 Feb 18:42    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:42    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:42    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:43    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-42-36.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      "  8%|█▊                   | 4/48 [02:25<26:00, 35.46s/trial, best loss: -0.2772]15 Feb 18:43    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  8%|█▊                   | 4/48 [02:25<26:00, 35.46s/trial, best loss: -0.2772]15 Feb 18:43    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:43    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:43    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:43    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:44    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-43-17.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 10%|██▏                  | 5/48 [03:23<31:21, 43.75s/trial, best loss: -0.2772]15 Feb 18:44    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 10%|██▏                  | 5/48 [03:23<31:21, 43.75s/trial, best loss: -0.2772]15 Feb 18:44    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:44    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:44    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:44    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-44-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 12%|██▋                  | 6/48 [04:23<34:29, 49.27s/trial, best loss: -0.2772]15 Feb 18:45    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 12%|██▋                  | 6/48 [04:23<34:29, 49.27s/trial, best loss: -0.2772]15 Feb 18:45    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:45    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-45-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 15%|███                  | 7/48 [04:54<29:29, 43.17s/trial, best loss: -0.2772]15 Feb 18:45    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 15%|███                  | 7/48 [04:54<29:29, 43.17s/trial, best loss: -0.2772]15 Feb 18:45    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:45    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:45    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-45-46.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 17%|███▌                 | 8/48 [05:14<23:56, 35.90s/trial, best loss: -0.2772]15 Feb 18:46    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 17%|███▌                 | 8/48 [05:14<23:56, 35.90s/trial, best loss: -0.2772]15 Feb 18:46    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:46    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-46-06.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 19%|███▉                 | 9/48 [05:53<23:56, 36.83s/trial, best loss: -0.2772]15 Feb 18:46    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 19%|███▉                 | 9/48 [05:53<23:56, 36.83s/trial, best loss: -0.2772]15 Feb 18:46    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:46    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:46    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:47    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-46-45.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 21%|████▏               | 10/48 [06:35<24:21, 38.45s/trial, best loss: -0.2772]15 Feb 18:47    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 21%|████▏               | 10/48 [06:35<24:21, 38.45s/trial, best loss: -0.2772]15 Feb 18:47    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:47    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:47    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:47    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-47-27.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 23%|████▌               | 11/48 [07:18<24:30, 39.75s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 23%|████▌               | 11/48 [07:18<24:30, 39.75s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:48    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-48-10.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 25%|█████               | 12/48 [07:39<20:32, 34.24s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 25%|█████               | 12/48 [07:40<20:32, 34.24s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:48    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-48-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 27%|█████▍              | 13/48 [08:01<17:50, 30.57s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 27%|█████▍              | 13/48 [08:02<17:50, 30.57s/trial, best loss: -0.2772]15 Feb 18:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:48    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:49    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-48-54.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 29%|█████▊              | 14/48 [08:37<18:12, 32.14s/trial, best loss: -0.2772]15 Feb 18:49    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 29%|█████▊              | 14/48 [08:38<18:12, 32.14s/trial, best loss: -0.2772]15 Feb 18:49    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:49    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:49    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:49    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-49-29.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 31%|██████▎             | 15/48 [09:12<18:11, 33.07s/trial, best loss: -0.2772]15 Feb 18:50    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 31%|██████▎             | 15/48 [09:13<18:11, 33.07s/trial, best loss: -0.2772]15 Feb 18:50    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:50    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-50-05.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 33%|██████▋             | 16/48 [09:34<15:48, 29.65s/trial, best loss: -0.2772]15 Feb 18:50    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 33%|██████▋             | 16/48 [09:34<15:48, 29.65s/trial, best loss: -0.2772]15 Feb 18:50    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:50    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:50    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:51    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-50-26.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 35%|███████             | 17/48 [10:14<16:56, 32.80s/trial, best loss: -0.2772]15 Feb 18:51    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 35%|███████             | 17/48 [10:15<16:56, 32.80s/trial, best loss: -0.2772]15 Feb 18:51    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:51    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:51    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:51    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:53    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-51-06.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 38%|███████▌            | 18/48 [12:24<31:01, 62.06s/trial, best loss: -0.2772]15 Feb 18:53    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 38%|███████▌            | 18/48 [12:25<31:01, 62.06s/trial, best loss: -0.2772]15 Feb 18:53    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:53    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:53    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:53    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-53-16.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 40%|███████▌           | 19/48 [16:22<55:30, 114.85s/trial, best loss: -0.2772]15 Feb 18:57    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 40%|███████▌           | 19/48 [16:23<55:30, 114.85s/trial, best loss: -0.2772]15 Feb 18:57    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:57    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-57-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 42%|████████▎           | 20/48 [17:06<43:38, 93.53s/trial, best loss: -0.2772]15 Feb 18:57    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 42%|████████▎           | 20/48 [17:06<43:38, 93.53s/trial, best loss: -0.2772]15 Feb 18:57    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:57    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:57    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:58    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-57-58.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 44%|████████▊           | 21/48 [17:29<32:34, 72.39s/trial, best loss: -0.2772]15 Feb 18:58    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 44%|████████▊           | 21/48 [17:30<32:34, 72.39s/trial, best loss: -0.2772]15 Feb 18:58    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:58    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:58    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:58    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 18:59    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-58-21.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 46%|█████████▏          | 22/48 [18:09<27:04, 62.48s/trial, best loss: -0.2772]15 Feb 18:59    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 46%|█████████▏          | 22/48 [18:09<27:04, 62.48s/trial, best loss: -0.2772]15 Feb 18:59    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 18:59    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 18:59    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 18:59    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:01    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_18-59-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 48%|█████████▌          | 23/48 [20:27<35:31, 85.25s/trial, best loss: -0.2772]15 Feb 19:01    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 48%|█████████▌          | 23/48 [20:27<35:31, 85.25s/trial, best loss: -0.2772]15 Feb 19:01    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:01    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:01    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:01    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:02    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-01-19.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 50%|██████████          | 24/48 [21:56<34:32, 86.35s/trial, best loss: -0.2772]15 Feb 19:02    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 50%|██████████          | 24/48 [21:56<34:32, 86.35s/trial, best loss: -0.2772]15 Feb 19:02    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:02    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:02    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:02    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:06    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-02-48.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 52%|█████████▉         | 25/48 [26:05<51:50, 135.24s/trial, best loss: -0.2772]15 Feb 19:06    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 52%|█████████▉         | 25/48 [26:05<51:50, 135.24s/trial, best loss: -0.2772]15 Feb 19:06    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:06    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:06    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:06    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:07    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-06-57.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 54%|██████████▎        | 26/48 [26:35<37:58, 103.58s/trial, best loss: -0.2772]15 Feb 19:07    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 54%|██████████▎        | 26/48 [26:35<37:58, 103.58s/trial, best loss: -0.2772]15 Feb 19:07    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:07    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:07    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:07    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-07-27.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 56%|███████████▎        | 27/48 [27:16<29:40, 84.77s/trial, best loss: -0.2772]15 Feb 19:08    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 56%|███████████▎        | 27/48 [27:16<29:40, 84.77s/trial, best loss: -0.2772]15 Feb 19:08    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:08    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-08-08.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 58%|███████████▋        | 28/48 [28:00<24:11, 72.58s/trial, best loss: -0.2772]15 Feb 19:08    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 58%|███████████▋        | 28/48 [28:00<24:11, 72.58s/trial, best loss: -0.2772]15 Feb 19:08    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:08    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:08    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:10    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-08-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 60%|████████████        | 29/48 [29:16<23:17, 73.53s/trial, best loss: -0.2772]15 Feb 19:10    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 60%|████████████        | 29/48 [29:16<23:17, 73.53s/trial, best loss: -0.2772]15 Feb 19:10    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:10    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:10    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:10    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:12    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-10-08.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 62%|████████████▌       | 30/48 [31:22<26:49, 89.43s/trial, best loss: -0.2772]15 Feb 19:12    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 62%|████████████▌       | 30/48 [31:22<26:49, 89.43s/trial, best loss: -0.2772]15 Feb 19:12    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:12    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-12-14.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2805                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2805)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3654)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 65%|████████████▎      | 31/48 [33:28<28:27, 100.44s/trial, best loss: -0.2805]15 Feb 19:14    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 65%|████████████▎      | 31/48 [33:29<28:27, 100.44s/trial, best loss: -0.2805]15 Feb 19:14    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:14    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-14-20.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 67%|█████████████▎      | 32/48 [33:59<21:10, 79.40s/trial, best loss: -0.2805]15 Feb 19:14    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 67%|█████████████▎      | 32/48 [33:59<21:10, 79.40s/trial, best loss: -0.2805]15 Feb 19:14    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:14    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:14    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-14-51.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 69%|█████████████▊      | 33/48 [36:22<24:41, 98.74s/trial, best loss: -0.2805]15 Feb 19:17    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 69%|█████████████▊      | 33/48 [36:23<24:41, 98.74s/trial, best loss: -0.2805]15 Feb 19:17    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:17    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-17-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 71%|██████████████▏     | 34/48 [36:39<17:17, 74.13s/trial, best loss: -0.2805]15 Feb 19:17    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 71%|██████████████▏     | 34/48 [36:39<17:17, 74.13s/trial, best loss: -0.2805]15 Feb 19:17    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:17    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:17    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-17-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 73%|██████████████▌     | 35/48 [37:10<13:12, 61.00s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 73%|██████████████▌     | 35/48 [37:10<13:12, 61.00s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:18    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-18-02.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 75%|███████████████     | 36/48 [37:23<09:19, 46.61s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 75%|███████████████     | 36/48 [37:23<09:19, 46.61s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:18    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-18-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 77%|███████████████▍    | 37/48 [37:49<07:26, 40.62s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 77%|███████████████▍    | 37/48 [37:49<07:26, 40.62s/trial, best loss: -0.2805]15 Feb 19:18    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:18    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:18    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-18-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 79%|███████████████▊    | 38/48 [39:09<08:43, 52.36s/trial, best loss: -0.2805]15 Feb 19:20    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 79%|███████████████▊    | 38/48 [39:09<08:43, 52.36s/trial, best loss: -0.2805]15 Feb 19:20    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:20    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-20-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 81%|████████████████▎   | 39/48 [39:58<07:43, 51.47s/trial, best loss: -0.2805]15 Feb 19:20    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 81%|████████████████▎   | 39/48 [39:59<07:43, 51.47s/trial, best loss: -0.2805]15 Feb 19:20    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:20    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:20    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-20-50.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 83%|████████████████▋   | 40/48 [41:24<08:13, 61.72s/trial, best loss: -0.2805]15 Feb 19:22    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 83%|████████████████▋   | 40/48 [41:24<08:13, 61.72s/trial, best loss: -0.2805]15 Feb 19:22    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:22    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-22-16.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 85%|█████████████████   | 41/48 [41:50<05:56, 50.99s/trial, best loss: -0.2805]15 Feb 19:22    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 85%|█████████████████   | 41/48 [41:50<05:56, 50.99s/trial, best loss: -0.2805]15 Feb 19:22    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:22    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:22    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-22-42.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2817                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2817)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3631)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 88%|█████████████████▌  | 42/48 [43:23<06:20, 63.48s/trial, best loss: -0.2817]15 Feb 19:24    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 88%|█████████████████▌  | 42/48 [43:23<06:20, 63.48s/trial, best loss: -0.2817]15 Feb 19:24    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:24    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-24-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 90%|█████████████████▉  | 43/48 [44:00<04:38, 55.79s/trial, best loss: -0.2817]15 Feb 19:24    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 90%|█████████████████▉  | 43/48 [44:01<04:38, 55.79s/trial, best loss: -0.2817]15 Feb 19:24    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:24    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:24    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:25    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-24-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 92%|██████████████████▎ | 44/48 [44:39<03:22, 50.66s/trial, best loss: -0.2817]15 Feb 19:25    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 92%|██████████████████▎ | 44/48 [44:39<03:22, 50.66s/trial, best loss: -0.2817]15 Feb 19:25    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:25    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:25    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:25    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-25-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 94%|██████████████████▊ | 45/48 [45:40<02:41, 53.68s/trial, best loss: -0.2817]15 Feb 19:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 94%|██████████████████▊ | 45/48 [45:40<02:41, 53.68s/trial, best loss: -0.2817]15 Feb 19:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:26    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-26-32.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 96%|███████████████████▏| 46/48 [46:40<01:51, 55.62s/trial, best loss: -0.2817]15 Feb 19:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 96%|███████████████████▏| 46/48 [46:40<01:51, 55.62s/trial, best loss: -0.2817]15 Feb 19:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:27    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-27-32.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 98%|███████████████████▌| 47/48 [47:08<00:47, 47.25s/trial, best loss: -0.2817]15 Feb 19:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 98%|███████████████████▌| 47/48 [47:08<00:47, 47.25s/trial, best loss: -0.2817]15 Feb 19:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm00/ml-100k_harm00-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:28    WARNING  Max value of user's history interaction records has reached 21.015873015873016% of the total.\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm00/MultiVAE-Feb-15-2023_19-28-00.pth\u001b[0m\n",
      "\n",
      "100%|████████████████████| 48/48 [47:29<00:00, 59.36s/trial, best loss: -0.2817]\n",
      "best params:  {'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "best result: \n",
      "{'model': 'MultiVAE', 'best_valid_score': 0.2817, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.2817)]), 'test_result': OrderedDict([('ndcg@10', 0.3631)])}\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 19:28    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 19:28    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-28-22.pth\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:28    WARNING  Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 19:28    WARNING    File \"/home/marta/jku/activity_fair//run_hyper.py\", line 127, in <module>\n",
      "    hyperopt_tune(args)\n",
      "  File \"/home/marta/jku/activity_fair//run_hyper.py\", line 39, in hyperopt_tune\n",
      "    hp.run()\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/quick_start/quick_start.py\", line 153, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\u001b[0m\n",
      "\n",
      "current best valid score: 0.2738                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2738)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3497)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      "  2%|▍                    | 1/48 [00:19<14:58, 19.12s/trial, best loss: -0.2738]15 Feb 19:28    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  2%|▍                    | 1/48 [00:19<14:58, 19.12s/trial, best loss: -0.2738]15 Feb 19:28    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-28-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      "  4%|▉                    | 2/48 [00:33<12:24, 16.18s/trial, best loss: -0.2738]15 Feb 19:28    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  4%|▉                    | 2/48 [00:33<12:24, 16.18s/trial, best loss: -0.2738]15 Feb 19:28    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:29    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-28-55.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  6%|█▎                   | 3/48 [01:19<22:31, 30.04s/trial, best loss: -0.2738]15 Feb 19:29    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  6%|█▎                   | 3/48 [01:20<22:31, 30.04s/trial, best loss: -0.2738]15 Feb 19:29    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:30    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-29-42.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2761                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2761)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3566)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      "  8%|█▊                   | 4/48 [01:56<24:01, 32.77s/trial, best loss: -0.2761]15 Feb 19:30    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  8%|█▊                   | 4/48 [01:56<24:01, 32.77s/trial, best loss: -0.2761]15 Feb 19:30    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:30    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:30    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:30    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-30-19.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 10%|██▏                  | 5/48 [02:37<25:38, 35.79s/trial, best loss: -0.2761]15 Feb 19:30    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 10%|██▏                  | 5/48 [02:38<25:38, 35.79s/trial, best loss: -0.2761]15 Feb 19:30    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:31    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-31-00.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 12%|██▋                  | 6/48 [02:50<19:32, 27.91s/trial, best loss: -0.2761]15 Feb 19:31    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 12%|██▋                  | 6/48 [02:50<19:32, 27.91s/trial, best loss: -0.2761]15 Feb 19:31    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:32    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-31-12.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 15%|███                  | 7/48 [03:57<27:49, 40.71s/trial, best loss: -0.2761]15 Feb 19:32    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 15%|███                  | 7/48 [03:57<27:49, 40.71s/trial, best loss: -0.2761]15 Feb 19:32    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:32    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:32    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:33    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-32-19.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2863                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2863)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3652)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 17%|███▌                 | 8/48 [05:32<38:34, 57.85s/trial, best loss: -0.2863]15 Feb 19:33    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 17%|███▌                 | 8/48 [05:32<38:34, 57.85s/trial, best loss: -0.2863]15 Feb 19:33    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:35    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-33-54.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 19%|███▉                 | 9/48 [07:19<47:40, 73.36s/trial, best loss: -0.2863]15 Feb 19:35    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 19%|███▉                 | 9/48 [07:19<47:40, 73.36s/trial, best loss: -0.2863]15 Feb 19:35    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:38    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-35-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 21%|███▌             | 10/48 [10:30<1:09:23, 109.57s/trial, best loss: -0.2863]15 Feb 19:38    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 21%|███▌             | 10/48 [10:30<1:09:23, 109.57s/trial, best loss: -0.2863]15 Feb 19:38    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:38    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:38    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-38-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 23%|████▌               | 11/48 [11:02<53:01, 85.97s/trial, best loss: -0.2863]15 Feb 19:39    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 23%|████▌               | 11/48 [11:02<53:01, 85.97s/trial, best loss: -0.2863]15 Feb 19:39    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-39-25.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 25%|█████               | 12/48 [11:25<39:58, 66.63s/trial, best loss: -0.2863]15 Feb 19:39    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 25%|█████               | 12/48 [11:25<39:58, 66.63s/trial, best loss: -0.2863]15 Feb 19:39    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:39    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-39-47.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 27%|█████▍              | 13/48 [11:48<31:11, 53.47s/trial, best loss: -0.2863]15 Feb 19:40    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 27%|█████▍              | 13/48 [11:48<31:11, 53.47s/trial, best loss: -0.2863]15 Feb 19:40    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-40-10.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 29%|█████▊              | 14/48 [12:14<25:35, 45.15s/trial, best loss: -0.2863]15 Feb 19:40    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 29%|█████▊              | 14/48 [12:14<25:35, 45.15s/trial, best loss: -0.2863]15 Feb 19:40    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:40    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-40-36.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2869                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2869)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3647)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 31%|██████▎             | 15/48 [13:46<32:38, 59.34s/trial, best loss: -0.2869]15 Feb 19:42    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 31%|██████▎             | 15/48 [13:46<32:38, 59.34s/trial, best loss: -0.2869]15 Feb 19:42    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-42-08.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 33%|██████▋             | 16/48 [14:16<26:54, 50.46s/trial, best loss: -0.2869]15 Feb 19:42    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 33%|██████▋             | 16/48 [14:16<26:54, 50.46s/trial, best loss: -0.2869]15 Feb 19:42    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:42    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:43    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-42-38.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 35%|███████             | 17/48 [15:00<25:03, 48.50s/trial, best loss: -0.2869]15 Feb 19:43    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 35%|███████             | 17/48 [15:00<25:03, 48.50s/trial, best loss: -0.2869]15 Feb 19:43    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:43    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:43    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:45    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-43-22.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 38%|███████▌            | 18/48 [16:44<32:38, 65.29s/trial, best loss: -0.2869]15 Feb 19:45    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 38%|███████▌            | 18/48 [16:44<32:38, 65.29s/trial, best loss: -0.2869]15 Feb 19:45    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:45    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:45    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:46    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-45-07.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 40%|███████▉            | 19/48 [17:53<32:01, 66.27s/trial, best loss: -0.2869]15 Feb 19:46    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 40%|███████▉            | 19/48 [17:53<32:01, 66.27s/trial, best loss: -0.2869]15 Feb 19:46    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:46    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:46    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:47    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-46-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 42%|████████▎           | 20/48 [19:38<36:25, 78.07s/trial, best loss: -0.2869]15 Feb 19:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 42%|████████▎           | 20/48 [19:38<36:25, 78.07s/trial, best loss: -0.2869]15 Feb 19:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-48-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 44%|████████▊           | 21/48 [20:25<30:52, 68.60s/trial, best loss: -0.2869]15 Feb 19:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 44%|████████▊           | 21/48 [20:25<30:52, 68.60s/trial, best loss: -0.2869]15 Feb 19:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-48-47.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 46%|█████████▏          | 22/48 [20:38<22:28, 51.86s/trial, best loss: -0.2869]15 Feb 19:49    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 46%|█████████▏          | 22/48 [20:38<22:28, 51.86s/trial, best loss: -0.2869]15 Feb 19:49    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:49    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:49    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:52    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-49-00.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 48%|█████████▌          | 23/48 [23:50<39:11, 94.04s/trial, best loss: -0.2869]15 Feb 19:52    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 48%|█████████▌          | 23/48 [23:50<39:11, 94.04s/trial, best loss: -0.2869]15 Feb 19:52    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:52    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:52    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-52-12.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 50%|██████████          | 24/48 [25:05<35:22, 88.45s/trial, best loss: -0.2869]15 Feb 19:53    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 50%|██████████          | 24/48 [25:06<35:22, 88.45s/trial, best loss: -0.2869]15 Feb 19:53    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-53-28.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 52%|██████████▍         | 25/48 [25:28<26:16, 68.56s/trial, best loss: -0.2869]15 Feb 19:53    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 52%|██████████▍         | 25/48 [25:28<26:16, 68.56s/trial, best loss: -0.2869]15 Feb 19:53    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:53    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:54    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-53-50.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 54%|██████████▊         | 26/48 [26:09<22:08, 60.39s/trial, best loss: -0.2869]15 Feb 19:54    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 54%|██████████▊         | 26/48 [26:09<22:08, 60.39s/trial, best loss: -0.2869]15 Feb 19:54    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:54    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:54    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:55    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-54-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 56%|███████████▎        | 27/48 [27:21<22:23, 63.96s/trial, best loss: -0.2869]15 Feb 19:55    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 56%|███████████▎        | 27/48 [27:21<22:23, 63.96s/trial, best loss: -0.2869]15 Feb 19:55    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:55    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:55    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-55-44.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 58%|███████████▋        | 28/48 [27:58<18:33, 55.70s/trial, best loss: -0.2869]15 Feb 19:56    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 58%|███████████▋        | 28/48 [27:58<18:33, 55.70s/trial, best loss: -0.2869]15 Feb 19:56    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-56-20.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 60%|████████████        | 29/48 [28:30<15:27, 48.84s/trial, best loss: -0.2869]15 Feb 19:56    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 60%|████████████        | 29/48 [28:31<15:27, 48.84s/trial, best loss: -0.2869]15 Feb 19:56    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:56    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-56-53.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 62%|████████████▌       | 30/48 [29:49<17:19, 57.73s/trial, best loss: -0.2869]15 Feb 19:58    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 62%|████████████▌       | 30/48 [29:49<17:19, 57.73s/trial, best loss: -0.2869]15 Feb 19:58    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-58-11.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 65%|████████████▉       | 31/48 [30:27<14:43, 51.96s/trial, best loss: -0.2869]15 Feb 19:58    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 65%|████████████▉       | 31/48 [30:28<14:43, 51.96s/trial, best loss: -0.2869]15 Feb 19:58    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 19:58    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_19-58-50.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 67%|█████████████▎      | 32/48 [31:42<15:40, 58.78s/trial, best loss: -0.2869]15 Feb 20:00    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 67%|█████████████▎      | 32/48 [31:42<15:40, 58.78s/trial, best loss: -0.2869]15 Feb 20:00    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-00-05.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 69%|█████████████▊      | 33/48 [32:08<12:13, 48.89s/trial, best loss: -0.2869]15 Feb 20:00    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 69%|█████████████▊      | 33/48 [32:08<12:13, 48.89s/trial, best loss: -0.2869]15 Feb 20:00    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:00    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-00-30.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 71%|██████████████▏     | 34/48 [32:44<10:30, 45.07s/trial, best loss: -0.2869]15 Feb 20:01    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 71%|██████████████▏     | 34/48 [32:44<10:30, 45.07s/trial, best loss: -0.2869]15 Feb 20:01    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-01-07.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 73%|██████████████▌     | 35/48 [33:09<08:27, 39.02s/trial, best loss: -0.2869]15 Feb 20:01    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 73%|██████████████▌     | 35/48 [33:09<08:27, 39.02s/trial, best loss: -0.2869]15 Feb 20:01    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:01    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-01-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 75%|███████████████     | 36/48 [34:56<11:54, 59.56s/trial, best loss: -0.2869]15 Feb 20:03    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 75%|███████████████     | 36/48 [34:57<11:54, 59.56s/trial, best loss: -0.2869]15 Feb 20:03    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-03-19.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 77%|███████████████▍    | 37/48 [35:11<08:26, 46.07s/trial, best loss: -0.2869]15 Feb 20:03    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 77%|███████████████▍    | 37/48 [35:11<08:26, 46.07s/trial, best loss: -0.2869]15 Feb 20:03    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:03    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:05    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-03-33.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 79%|███████████████▊    | 38/48 [36:41<09:53, 59.31s/trial, best loss: -0.2869]15 Feb 20:05    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 79%|███████████████▊    | 38/48 [36:41<09:53, 59.31s/trial, best loss: -0.2869]15 Feb 20:05    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:05    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:05    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:06    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-05-04.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 81%|████████████████▎   | 39/48 [38:01<09:49, 65.46s/trial, best loss: -0.2869]15 Feb 20:06    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 81%|████████████████▎   | 39/48 [38:01<09:49, 65.46s/trial, best loss: -0.2869]15 Feb 20:06    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:06    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:06    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:07    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-06-23.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 83%|████████████████▋   | 40/48 [39:20<09:17, 69.64s/trial, best loss: -0.2869]15 Feb 20:07    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 83%|████████████████▋   | 40/48 [39:21<09:17, 69.64s/trial, best loss: -0.2869]15 Feb 20:07    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:07    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:07    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:08    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-07-43.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 85%|█████████████████   | 41/48 [39:45<06:33, 56.23s/trial, best loss: -0.2869]15 Feb 20:08    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 85%|█████████████████   | 41/48 [39:46<06:33, 56.23s/trial, best loss: -0.2869]15 Feb 20:08    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:08    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:08    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:10    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-08-08.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 88%|█████████████████▌  | 42/48 [42:19<08:32, 85.49s/trial, best loss: -0.2869]15 Feb 20:10    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 88%|█████████████████▌  | 42/48 [42:19<08:32, 85.49s/trial, best loss: -0.2869]15 Feb 20:10    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:10    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:10    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-10-42.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 90%|█████████████████▉  | 43/48 [42:38<05:27, 65.57s/trial, best loss: -0.2869]15 Feb 20:11    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 90%|█████████████████▉  | 43/48 [42:38<05:27, 65.57s/trial, best loss: -0.2869]15 Feb 20:11    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-11-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 92%|██████████████████▎ | 44/48 [43:10<03:41, 55.37s/trial, best loss: -0.2869]15 Feb 20:11    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 92%|██████████████████▎ | 44/48 [43:10<03:41, 55.37s/trial, best loss: -0.2869]15 Feb 20:11    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:11    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-11-32.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 94%|██████████████████▊ | 45/48 [45:45<04:15, 85.24s/trial, best loss: -0.2869]15 Feb 20:14    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 94%|██████████████████▊ | 45/48 [45:45<04:15, 85.24s/trial, best loss: -0.2869]15 Feb 20:14    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-14-07.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 96%|███████████████████▏| 46/48 [46:26<02:24, 72.08s/trial, best loss: -0.2869]15 Feb 20:14    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 96%|███████████████████▏| 46/48 [46:26<02:24, 72.08s/trial, best loss: -0.2869]15 Feb 20:14    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:14    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-14-49.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 98%|███████████████████▌| 47/48 [47:55<01:17, 77.18s/trial, best loss: -0.2869]15 Feb 20:16    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 98%|███████████████████▌| 47/48 [47:55<01:17, 77.18s/trial, best loss: -0.2869]15 Feb 20:16    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm01/ml-100k_harm01-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm01/MultiVAE-Feb-15-2023_20-16-18.pth\u001b[0m\n",
      "\n",
      "100%|████████████████████| 48/48 [48:18<00:00, 60.38s/trial, best loss: -0.2869]\n",
      "best params:  {'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "best result: \n",
      "{'model': 'MultiVAE', 'best_valid_score': 0.2869, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.2869)]), 'test_result': OrderedDict([('ndcg@10', 0.3647)])}\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 20:16    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 20:16    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:16    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:17    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-16-42.pth\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 20:17    WARNING  Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 20:17    WARNING    File \"/home/marta/jku/activity_fair//run_hyper.py\", line 127, in <module>\n",
      "    hyperopt_tune(args)\n",
      "  File \"/home/marta/jku/activity_fair//run_hyper.py\", line 39, in hyperopt_tune\n",
      "    hp.run()\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/quick_start/quick_start.py\", line 153, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\u001b[0m\n",
      "\n",
      "current best valid score: 0.2857                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2857)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3576)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  2%|▍                    | 1/48 [00:26<21:02, 26.86s/trial, best loss: -0.2857]15 Feb 20:17    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  2%|▍                    | 1/48 [00:27<21:02, 26.86s/trial, best loss: -0.2857]15 Feb 20:17    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:17    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:17    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:19    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-17-09.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "  4%|▊                  | 2/48 [02:57<1:16:11, 99.39s/trial, best loss: -0.2857]15 Feb 20:19    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  4%|▊                  | 2/48 [02:57<1:16:11, 99.39s/trial, best loss: -0.2857]15 Feb 20:19    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:19    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:19    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:20    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-19-39.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2894                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2894)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3675)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "  6%|█▏                 | 3/48 [04:16<1:07:34, 90.11s/trial, best loss: -0.2894]15 Feb 20:20    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  6%|█▏                 | 3/48 [04:16<1:07:34, 90.11s/trial, best loss: -0.2894]15 Feb 20:20    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:20    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:20    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-20-58.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "  8%|█▌                | 4/48 [06:47<1:23:50, 114.33s/trial, best loss: -0.2894]15 Feb 20:23    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  8%|█▌                | 4/48 [06:47<1:23:50, 114.33s/trial, best loss: -0.2894]15 Feb 20:23    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-23-29.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 10%|██▏                  | 5/48 [07:11<58:35, 81.76s/trial, best loss: -0.2894]15 Feb 20:23    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 10%|██▏                  | 5/48 [07:11<58:35, 81.76s/trial, best loss: -0.2894]15 Feb 20:23    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:23    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:24    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-23-53.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 12%|██▋                  | 6/48 [07:34<43:19, 61.88s/trial, best loss: -0.2894]15 Feb 20:24    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 12%|██▋                  | 6/48 [07:35<43:19, 61.88s/trial, best loss: -0.2894]15 Feb 20:24    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:24    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:24    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-24-17.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 15%|███                  | 7/48 [08:37<42:31, 62.24s/trial, best loss: -0.2894]15 Feb 20:25    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 15%|███                  | 7/48 [08:38<42:31, 62.24s/trial, best loss: -0.2894]15 Feb 20:25    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-25-19.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 17%|███▌                 | 8/48 [09:09<34:57, 52.43s/trial, best loss: -0.2894]15 Feb 20:25    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 17%|███▌                 | 8/48 [09:09<34:57, 52.43s/trial, best loss: -0.2894]15 Feb 20:25    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:25    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-25-51.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 19%|███▉                 | 9/48 [09:40<29:47, 45.82s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 19%|███▉                 | 9/48 [09:40<29:47, 45.82s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-26-22.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 21%|████▏               | 10/48 [09:53<22:33, 35.62s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 21%|████▏               | 10/48 [09:53<22:33, 35.62s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-26-35.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 23%|████▌               | 11/48 [10:09<18:19, 29.72s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 23%|████▌               | 11/48 [10:09<18:19, 29.72s/trial, best loss: -0.2894]15 Feb 20:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-26-51.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 25%|█████               | 12/48 [10:33<16:47, 27.98s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 25%|█████               | 12/48 [10:33<16:47, 27.98s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-27-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 27%|█████▍              | 13/48 [10:53<14:57, 25.65s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 27%|█████▍              | 13/48 [10:54<14:57, 25.65s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-27-36.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 29%|█████▊              | 14/48 [11:15<13:54, 24.54s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 29%|█████▊              | 14/48 [11:16<13:54, 24.54s/trial, best loss: -0.2894]15 Feb 20:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:28    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-27-58.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 31%|██████▎             | 15/48 [12:09<18:15, 33.21s/trial, best loss: -0.2894]15 Feb 20:28    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 31%|██████▎             | 15/48 [12:09<18:15, 33.21s/trial, best loss: -0.2894]15 Feb 20:28    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:28    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:28    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-28-51.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 33%|██████▋             | 16/48 [12:32<16:08, 30.27s/trial, best loss: -0.2894]15 Feb 20:29    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 33%|██████▋             | 16/48 [12:32<16:08, 30.27s/trial, best loss: -0.2894]15 Feb 20:29    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-29-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 35%|███████             | 17/48 [12:59<15:06, 29.25s/trial, best loss: -0.2894]15 Feb 20:29    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 35%|███████             | 17/48 [12:59<15:06, 29.25s/trial, best loss: -0.2894]15 Feb 20:29    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:30    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-29-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 38%|███████▌            | 18/48 [13:30<14:55, 29.83s/trial, best loss: -0.2894]15 Feb 20:30    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 38%|███████▌            | 18/48 [13:30<14:55, 29.83s/trial, best loss: -0.2894]15 Feb 20:30    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:30    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:30    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-30-12.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 40%|███████▉            | 19/48 [14:33<19:08, 39.60s/trial, best loss: -0.2894]15 Feb 20:31    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 40%|███████▉            | 19/48 [14:33<19:08, 39.60s/trial, best loss: -0.2894]15 Feb 20:31    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-31-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 42%|████████▎           | 20/48 [14:51<15:33, 33.34s/trial, best loss: -0.2894]15 Feb 20:31    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 42%|████████▎           | 20/48 [14:52<15:33, 33.34s/trial, best loss: -0.2894]15 Feb 20:31    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:32    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-31-34.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 44%|████████▊           | 21/48 [16:10<21:07, 46.96s/trial, best loss: -0.2894]15 Feb 20:32    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 44%|████████▊           | 21/48 [16:10<21:07, 46.96s/trial, best loss: -0.2894]15 Feb 20:32    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:32    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:32    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-32-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 46%|█████████▏          | 22/48 [17:27<24:15, 55.99s/trial, best loss: -0.2894]15 Feb 20:34    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 46%|█████████▏          | 22/48 [17:27<24:15, 55.99s/trial, best loss: -0.2894]15 Feb 20:34    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-34-09.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 48%|█████████▌          | 23/48 [17:47<18:51, 45.26s/trial, best loss: -0.2894]15 Feb 20:34    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 48%|█████████▌          | 23/48 [17:48<18:51, 45.26s/trial, best loss: -0.2894]15 Feb 20:34    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:34    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:35    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-34-30.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 50%|██████████          | 24/48 [18:38<18:48, 47.02s/trial, best loss: -0.2894]15 Feb 20:35    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 50%|██████████          | 24/48 [18:39<18:48, 47.02s/trial, best loss: -0.2894]15 Feb 20:35    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-35-21.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 52%|██████████▍         | 25/48 [19:49<20:41, 53.97s/trial, best loss: -0.2894]15 Feb 20:36    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 52%|██████████▍         | 25/48 [19:49<20:41, 53.97s/trial, best loss: -0.2894]15 Feb 20:36    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-36-31.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 54%|██████████▊         | 26/48 [20:03<15:25, 42.07s/trial, best loss: -0.2894]15 Feb 20:36    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 54%|██████████▊         | 26/48 [20:03<15:25, 42.07s/trial, best loss: -0.2894]15 Feb 20:36    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:36    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-36-45.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 56%|███████████▎        | 27/48 [20:33<13:26, 38.41s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 56%|███████████▎        | 27/48 [20:33<13:26, 38.41s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-37-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 58%|███████████▋        | 28/48 [20:52<10:52, 32.61s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 58%|███████████▋        | 28/48 [20:52<10:52, 32.61s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-37-34.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 60%|████████████        | 29/48 [21:08<08:47, 27.74s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 60%|████████████        | 29/48 [21:09<08:47, 27.74s/trial, best loss: -0.2894]15 Feb 20:37    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:37    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:38    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-37-50.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 62%|████████████▌       | 30/48 [22:02<10:42, 35.67s/trial, best loss: -0.2894]15 Feb 20:38    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 62%|████████████▌       | 30/48 [22:03<10:42, 35.67s/trial, best loss: -0.2894]15 Feb 20:38    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:38    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:38    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:39    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-38-45.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 65%|████████████▉       | 31/48 [22:57<11:41, 41.24s/trial, best loss: -0.2894]15 Feb 20:39    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 65%|████████████▉       | 31/48 [22:57<11:41, 41.24s/trial, best loss: -0.2894]15 Feb 20:39    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:39    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:39    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:40    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-39-39.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 67%|█████████████▎      | 32/48 [24:12<13:45, 51.60s/trial, best loss: -0.2894]15 Feb 20:40    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 67%|█████████████▎      | 32/48 [24:13<13:45, 51.60s/trial, best loss: -0.2894]15 Feb 20:40    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:40    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:40    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:42    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-40-55.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 69%|█████████████▊      | 33/48 [25:57<16:50, 67.37s/trial, best loss: -0.2894]15 Feb 20:42    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 69%|█████████████▊      | 33/48 [25:57<16:50, 67.37s/trial, best loss: -0.2894]15 Feb 20:42    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:42    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:42    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:43    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-42-39.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 71%|██████████████▏     | 34/48 [27:12<16:17, 69.84s/trial, best loss: -0.2894]15 Feb 20:43    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 71%|██████████████▏     | 34/48 [27:12<16:17, 69.84s/trial, best loss: -0.2894]15 Feb 20:43    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:43    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:43    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:45    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-43-54.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 73%|██████████████▌     | 35/48 [28:57<17:22, 80.17s/trial, best loss: -0.2894]15 Feb 20:45    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 73%|██████████████▌     | 35/48 [28:57<17:22, 80.17s/trial, best loss: -0.2894]15 Feb 20:45    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:45    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:45    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:46    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-45-39.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 75%|███████████████     | 36/48 [30:16<16:00, 80.06s/trial, best loss: -0.2894]15 Feb 20:46    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 75%|███████████████     | 36/48 [30:17<16:00, 80.06s/trial, best loss: -0.2894]15 Feb 20:46    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:46    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:46    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:47    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-46-59.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 77%|███████████████▍    | 37/48 [30:38<11:27, 62.50s/trial, best loss: -0.2894]15 Feb 20:47    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 77%|███████████████▍    | 37/48 [30:38<11:27, 62.50s/trial, best loss: -0.2894]15 Feb 20:47    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:47    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:47    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:48    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-47-20.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 79%|███████████████▊    | 38/48 [31:32<09:59, 59.97s/trial, best loss: -0.2894]15 Feb 20:48    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 79%|███████████████▊    | 38/48 [31:32<09:59, 59.97s/trial, best loss: -0.2894]15 Feb 20:48    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:48    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:48    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:49    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-48-14.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 81%|████████████████▎   | 39/48 [32:50<09:47, 65.33s/trial, best loss: -0.2894]15 Feb 20:49    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 81%|████████████████▎   | 39/48 [32:50<09:47, 65.33s/trial, best loss: -0.2894]15 Feb 20:49    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:49    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:49    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:50    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-49-32.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 83%|████████████████▋   | 40/48 [34:10<09:18, 69.79s/trial, best loss: -0.2894]15 Feb 20:50    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 83%|████████████████▋   | 40/48 [34:10<09:18, 69.79s/trial, best loss: -0.2894]15 Feb 20:50    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:50    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:50    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:51    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-50-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 85%|█████████████████   | 41/48 [35:08<07:42, 66.13s/trial, best loss: -0.2894]15 Feb 20:51    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 85%|█████████████████   | 41/48 [35:08<07:42, 66.13s/trial, best loss: -0.2894]15 Feb 20:51    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:51    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:51    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:52    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-51-50.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 88%|█████████████████▌  | 42/48 [35:46<05:46, 57.71s/trial, best loss: -0.2894]15 Feb 20:52    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 88%|█████████████████▌  | 42/48 [35:46<05:46, 57.71s/trial, best loss: -0.2894]15 Feb 20:52    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:52    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:52    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:53    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-52-28.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 90%|█████████████████▉  | 43/48 [36:37<04:39, 55.95s/trial, best loss: -0.2894]15 Feb 20:53    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 90%|█████████████████▉  | 43/48 [36:38<04:39, 55.95s/trial, best loss: -0.2894]15 Feb 20:53    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:53    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:53    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:54    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-53-20.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 92%|██████████████████▎ | 44/48 [37:57<04:12, 63.07s/trial, best loss: -0.2894]15 Feb 20:54    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 92%|██████████████████▎ | 44/48 [37:57<04:12, 63.07s/trial, best loss: -0.2894]15 Feb 20:54    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:54    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:54    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-54-39.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 94%|██████████████████▊ | 45/48 [38:19<02:32, 50.68s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 94%|██████████████████▊ | 45/48 [38:19<02:32, 50.68s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-55-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 96%|███████████████████▏| 46/48 [38:56<01:33, 46.70s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 96%|███████████████████▏| 46/48 [38:57<01:33, 46.70s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-55-39.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 98%|███████████████████▌| 47/48 [39:11<00:37, 37.06s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 98%|███████████████████▌| 47/48 [39:11<00:37, 37.06s/trial, best loss: -0.2894]15 Feb 20:55    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm05/ml-100k_harm05-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:55    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:56    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm05/MultiVAE-Feb-15-2023_20-55-53.pth\u001b[0m\n",
      "\n",
      "100%|████████████████████| 48/48 [39:24<00:00, 49.26s/trial, best loss: -0.2894]\n",
      "best params:  {'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "best result: \n",
      "{'model': 'MultiVAE', 'best_valid_score': 0.2894, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.2894)]), 'test_result': OrderedDict([('ndcg@10', 0.3675)])}\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 20:56    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  0%|                                    | 0/48 [00:00<?, ?trial/s, best loss=?]15 Feb 20:56    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:56    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:56    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:56    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_20-56-08.pth\u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 20:57    WARNING  Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \u001b[0m\n",
      "\n",
      "\u001b[33m15 Feb 20:57    WARNING    File \"/home/marta/jku/activity_fair//run_hyper.py\", line 127, in <module>\n",
      "    hyperopt_tune(args)\n",
      "  File \"/home/marta/jku/activity_fair//run_hyper.py\", line 39, in hyperopt_tune\n",
      "    hp.run()\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 413, in run\n",
      "    fmin(\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 553, in fmin\n",
      "    rval.exhaust()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 356, in exhaust\n",
      "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 292, in run\n",
      "    self.serial_evaluate()\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/fmin.py\", line 170, in serial_evaluate\n",
      "    result = self.domain.evaluate(spec, ctrl)\n",
      "  File \"/home/marta/miniconda3/envs/recbole/lib/python3.8/site-packages/hyperopt/base.py\", line 907, in evaluate\n",
      "    rval = self.fn(pyll_rval)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/trainer/hyper_tuning.py\", line 348, in trial\n",
      "    result_dict = self.objective_function(config_dict, self.fixed_config_file_list)\n",
      "  File \"/home/marta/jku/activity_fair/recbole/quick_start/quick_start.py\", line 153, in objective_function\n",
      "    tune.report(**test_result)\n",
      "\u001b[0m\n",
      "\n",
      "current best valid score: 0.2648                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2648)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3512)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  2%|▍                    | 1/48 [00:53<41:38, 53.15s/trial, best loss: -0.2648]15 Feb 20:57    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  2%|▍                    | 1/48 [00:53<41:38, 53.15s/trial, best loss: -0.2648]15 Feb 20:57    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:57    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:57    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:58    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_20-57-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      "  4%|▊                  | 2/48 [02:31<1:00:56, 79.50s/trial, best loss: -0.2648]15 Feb 20:58    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  4%|▊                  | 2/48 [02:31<1:00:56, 79.50s/trial, best loss: -0.2648]15 Feb 20:58    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:58    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:58    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_20-58-39.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2794                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2794)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3662)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      "  6%|█▎                   | 3/48 [02:54<40:24, 53.88s/trial, best loss: -0.2794]15 Feb 20:59    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  6%|█▎                   | 3/48 [02:54<40:24, 53.88s/trial, best loss: -0.2794]15 Feb 20:59    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_20-59-02.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      "  8%|█▊                   | 4/48 [03:47<39:23, 53.72s/trial, best loss: -0.2794]15 Feb 20:59    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      "  8%|█▊                   | 4/48 [03:48<39:23, 53.72s/trial, best loss: -0.2794]15 Feb 20:59    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 20:59    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_20-59-56.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 10%|██▏                  | 5/48 [05:32<51:43, 72.17s/trial, best loss: -0.2794]15 Feb 21:01    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 10%|██▏                  | 5/48 [05:33<51:43, 72.17s/trial, best loss: -0.2794]15 Feb 21:01    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-01-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 12%|██▋                  | 6/48 [05:48<37:08, 53.07s/trial, best loss: -0.2794]15 Feb 21:01    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 12%|██▋                  | 6/48 [05:49<37:08, 53.07s/trial, best loss: -0.2794]15 Feb 21:01    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:01    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-01-57.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 15%|███                  | 7/48 [06:26<32:46, 47.96s/trial, best loss: -0.2794]15 Feb 21:02    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 15%|███                  | 7/48 [06:26<32:46, 47.96s/trial, best loss: -0.2794]15 Feb 21:02    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-02-34.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 17%|███▌                 | 8/48 [06:40<24:49, 37.23s/trial, best loss: -0.2794]15 Feb 21:02    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 17%|███▌                 | 8/48 [06:40<24:49, 37.23s/trial, best loss: -0.2794]15 Feb 21:02    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:02    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-02-48.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 19%|███▉                 | 9/48 [07:12<23:09, 35.63s/trial, best loss: -0.2794]15 Feb 21:03    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 19%|███▉                 | 9/48 [07:12<23:09, 35.63s/trial, best loss: -0.2794]15 Feb 21:03    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-03-20.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 21%|████▏               | 10/48 [07:38<20:42, 32.70s/trial, best loss: -0.2794]15 Feb 21:03    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 21%|████▏               | 10/48 [07:39<20:42, 32.70s/trial, best loss: -0.2794]15 Feb 21:03    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:03    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:04    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-03-47.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 23%|████▌               | 11/48 [07:57<17:30, 28.39s/trial, best loss: -0.2794]15 Feb 21:04    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 23%|████▌               | 11/48 [07:57<17:30, 28.39s/trial, best loss: -0.2794]15 Feb 21:04    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:04    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:04    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:06    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-04-05.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 25%|█████               | 12/48 [10:22<38:16, 63.78s/trial, best loss: -0.2794]15 Feb 21:06    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 25%|█████               | 12/48 [10:22<38:16, 63.78s/trial, best loss: -0.2794]15 Feb 21:06    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:06    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:06    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:07    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-06-30.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 27%|█████▍              | 13/48 [10:54<31:36, 54.18s/trial, best loss: -0.2794]15 Feb 21:07    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 27%|█████▍              | 13/48 [10:54<31:36, 54.18s/trial, best loss: -0.2794]15 Feb 21:07    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:07    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:07    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:08    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-07-02.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 29%|█████▊              | 14/48 [12:23<36:47, 64.92s/trial, best loss: -0.2794]15 Feb 21:08    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 29%|█████▊              | 14/48 [12:24<36:47, 64.92s/trial, best loss: -0.2794]15 Feb 21:08    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:08    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:08    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-08-32.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 31%|██████▎             | 15/48 [13:53<39:49, 72.40s/trial, best loss: -0.2794]15 Feb 21:10    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 31%|██████▎             | 15/48 [13:53<39:49, 72.40s/trial, best loss: -0.2794]15 Feb 21:10    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-10-01.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 33%|██████▋             | 16/48 [14:46<35:30, 66.56s/trial, best loss: -0.2794]15 Feb 21:10    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 33%|██████▋             | 16/48 [14:46<35:30, 66.56s/trial, best loss: -0.2794]15 Feb 21:10    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:10    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:12    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-10-54.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2860                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.286)])                                               \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3757)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 35%|███████▍             | 17/48 [16:02<35:51, 69.41s/trial, best loss: -0.286]15 Feb 21:12    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 35%|███████▍             | 17/48 [16:02<35:51, 69.41s/trial, best loss: -0.286]15 Feb 21:12    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:12    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:12    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:13    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-12-10.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 38%|███████▉             | 18/48 [17:41<39:05, 78.20s/trial, best loss: -0.286]15 Feb 21:13    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 38%|███████▉             | 18/48 [17:41<39:05, 78.20s/trial, best loss: -0.286]15 Feb 21:13    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:13    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:13    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:14    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-13-49.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 40%|████████▎            | 19/48 [18:52<36:45, 76.07s/trial, best loss: -0.286]15 Feb 21:15    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 40%|████████▎            | 19/48 [18:52<36:45, 76.07s/trial, best loss: -0.286]15 Feb 21:15    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:15    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:15    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:15    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-15-00.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 42%|████████▊            | 20/48 [19:28<29:50, 63.95s/trial, best loss: -0.286]15 Feb 21:15    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 42%|████████▊            | 20/48 [19:28<29:50, 63.95s/trial, best loss: -0.286]15 Feb 21:15    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:15    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:15    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:16    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-15-36.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 44%|█████████▏           | 21/48 [20:22<27:29, 61.10s/trial, best loss: -0.286]15 Feb 21:16    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 44%|█████████▏           | 21/48 [20:22<27:29, 61.10s/trial, best loss: -0.286]15 Feb 21:16    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:16    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:16    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-16-30.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 46%|█████████▋           | 22/48 [21:01<23:37, 54.50s/trial, best loss: -0.286]15 Feb 21:17    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 46%|█████████▋           | 22/48 [21:02<23:37, 54.50s/trial, best loss: -0.286]15 Feb 21:17    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-17-10.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 48%|██████████           | 23/48 [21:49<21:51, 52.47s/trial, best loss: -0.286]15 Feb 21:17    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 48%|██████████           | 23/48 [21:49<21:51, 52.47s/trial, best loss: -0.286]15 Feb 21:17    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:17    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-17-57.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 50%|██████████▌          | 24/48 [22:28<19:25, 48.56s/trial, best loss: -0.286]15 Feb 21:18    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 50%|██████████▌          | 24/48 [22:29<19:25, 48.56s/trial, best loss: -0.286]15 Feb 21:18    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-18-37.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 52%|██████████▉          | 25/48 [22:44<14:47, 38.58s/trial, best loss: -0.286]15 Feb 21:18    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 52%|██████████▉          | 25/48 [22:44<14:47, 38.58s/trial, best loss: -0.286]15 Feb 21:18    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:18    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:19    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-18-52.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 54%|███████████▍         | 26/48 [23:47<16:52, 46.00s/trial, best loss: -0.286]15 Feb 21:19    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 54%|███████████▍         | 26/48 [23:47<16:52, 46.00s/trial, best loss: -0.286]15 Feb 21:19    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:19    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:19    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-19-55.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 56%|███████████▊         | 27/48 [25:00<18:54, 54.02s/trial, best loss: -0.286]15 Feb 21:21    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 56%|███████████▊         | 27/48 [25:00<18:54, 54.02s/trial, best loss: -0.286]15 Feb 21:21    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-21-08.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 58%|████████████▎        | 28/48 [25:28<15:24, 46.23s/trial, best loss: -0.286]15 Feb 21:21    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 58%|████████████▎        | 28/48 [25:28<15:24, 46.23s/trial, best loss: -0.286]15 Feb 21:21    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:21    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:22    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-21-36.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 60%|████████████▋        | 29/48 [25:54<12:43, 40.19s/trial, best loss: -0.286]15 Feb 21:22    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 60%|████████████▋        | 29/48 [25:54<12:43, 40.19s/trial, best loss: -0.286]15 Feb 21:22    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:22    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:22    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:23    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-22-02.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 62%|█████████████▏       | 30/48 [27:04<14:44, 49.14s/trial, best loss: -0.286]15 Feb 21:23    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 62%|█████████████▏       | 30/48 [27:04<14:44, 49.14s/trial, best loss: -0.286]15 Feb 21:23    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:23    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:23    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-23-12.pth\u001b[0m\n",
      "\n",
      "current best valid score: 0.2865                                                \n",
      "current best valid result:                                                      \n",
      "OrderedDict([('ndcg@10', 0.2865)])                                              \n",
      "current test result:                                                            \n",
      "OrderedDict([('ndcg@10', 0.3758)])                                              \n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 65%|████████████▉       | 31/48 [28:20<16:14, 57.35s/trial, best loss: -0.2865]15 Feb 21:24    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 65%|████████████▉       | 31/48 [28:21<16:14, 57.35s/trial, best loss: -0.2865]15 Feb 21:24    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-24-29.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 67%|█████████████▎      | 32/48 [28:40<12:15, 45.98s/trial, best loss: -0.2865]15 Feb 21:24    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 67%|█████████████▎      | 32/48 [28:40<12:15, 45.98s/trial, best loss: -0.2865]15 Feb 21:24    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:24    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:25    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-24-48.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 69%|█████████████▊      | 33/48 [29:35<12:08, 48.59s/trial, best loss: -0.2865]15 Feb 21:25    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 69%|█████████████▊      | 33/48 [29:35<12:08, 48.59s/trial, best loss: -0.2865]15 Feb 21:25    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:25    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:25    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-25-43.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 71%|██████████████▏     | 34/48 [30:06<10:10, 43.59s/trial, best loss: -0.2865]15 Feb 21:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 71%|██████████████▏     | 34/48 [30:07<10:10, 43.59s/trial, best loss: -0.2865]15 Feb 21:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-26-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 73%|██████████████▌     | 35/48 [30:33<08:19, 38.39s/trial, best loss: -0.2865]15 Feb 21:26    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 73%|██████████████▌     | 35/48 [30:33<08:19, 38.39s/trial, best loss: -0.2865]15 Feb 21:26    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:26    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:27    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-26-41.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 75%|███████████████     | 36/48 [31:01<07:05, 35.44s/trial, best loss: -0.2865]15 Feb 21:27    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 75%|███████████████     | 36/48 [31:02<07:05, 35.44s/trial, best loss: -0.2865]15 Feb 21:27    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:27    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:27    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:29    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-27-10.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 100000.0}\n",
      " 77%|███████████████▍    | 37/48 [33:25<12:27, 67.94s/trial, best loss: -0.2865]15 Feb 21:29    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 77%|███████████████▍    | 37/48 [33:25<12:27, 67.94s/trial, best loss: -0.2865]15 Feb 21:29    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:29    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:29    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:30    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-29-33.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 79%|███████████████▊    | 38/48 [34:03<09:49, 58.91s/trial, best loss: -0.2865]15 Feb 21:30    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 79%|███████████████▊    | 38/48 [34:03<09:49, 58.91s/trial, best loss: -0.2865]15 Feb 21:30    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:30    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:30    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-30-11.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 81%|████████████████▎   | 39/48 [35:14<09:23, 62.57s/trial, best loss: -0.2865]15 Feb 21:31    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 81%|████████████████▎   | 39/48 [35:14<09:23, 62.57s/trial, best loss: -0.2865]15 Feb 21:31    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-31-22.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.0001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 83%|████████████████▋   | 40/48 [35:47<07:09, 53.75s/trial, best loss: -0.2865]15 Feb 21:31    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 83%|████████████████▋   | 40/48 [35:47<07:09, 53.75s/trial, best loss: -0.2865]15 Feb 21:31    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:31    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-31-55.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 85%|█████████████████   | 41/48 [37:01<06:57, 59.66s/trial, best loss: -0.2865]15 Feb 21:33    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 85%|█████████████████   | 41/48 [37:01<06:57, 59.66s/trial, best loss: -0.2865]15 Feb 21:33    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-33-09.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.0001, 'mlp_hidden_size': '[1000]', 'total_anneal_steps': 5000.0}\n",
      " 88%|█████████████████▌  | 42/48 [37:20<04:45, 47.57s/trial, best loss: -0.2865]15 Feb 21:33    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 88%|█████████████████▌  | 42/48 [37:20<04:45, 47.57s/trial, best loss: -0.2865]15 Feb 21:33    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:33    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-33-28.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.005, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 90%|█████████████████▉  | 43/48 [39:07<05:26, 65.36s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 90%|█████████████████▉  | 43/48 [39:07<05:26, 65.36s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-35-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 92%|██████████████████▎ | 44/48 [39:30<03:30, 52.63s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 92%|██████████████████▎ | 44/48 [39:30<03:30, 52.63s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-35-38.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 94%|██████████████████▊ | 45/48 [39:49<02:08, 42.67s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 94%|██████████████████▊ | 45/48 [39:49<02:08, 42.67s/trial, best loss: -0.2865]15 Feb 21:35    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:35    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-35-57.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 100, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      " 96%|███████████████████▏| 46/48 [40:07<01:10, 35.15s/trial, best loss: -0.2865]15 Feb 21:36    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 96%|███████████████████▏| 46/48 [40:07<01:10, 35.15s/trial, best loss: -0.2865]15 Feb 21:36    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-36-15.pth\u001b[0m\n",
      "\n",
      "running parameters:                                                             \n",
      "{'anneal_cap': 1.0, 'latent_dimension': 500, 'learning_rate': 0.01, 'mlp_hidden_size': '[]', 'total_anneal_steps': 100000.0}\n",
      " 98%|███████████████████▌| 47/48 [40:25<00:29, 29.95s/trial, best loss: -0.2865]15 Feb 21:36    INFO  \u001b[1;35mSaving filtered dataset into \u001b[0m[/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-dataset.pth]\u001b[0m\n",
      "\n",
      "phases: 3\t datasets: 3                                                          \n",
      " 98%|███████████████████▌| 47/48 [40:25<00:29, 29.95s/trial, best loss: -0.2865]15 Feb 21:36    INFO  \u001b[1;35mSaving split dataloaders into\u001b[0m: [/home/marta/jku/activity_fair/saved/ml-100k_harm10/ml-100k_harm10-for-MultiVAE-dataloader.pth]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  \u001b[1;35m[Training]: \u001b[0m\u001b[1;36mtrain_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m train_neg_sample_args\u001b[0m: \u001b[1;33m[{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  \u001b[1;35m[Evaluation]: \u001b[0m\u001b[1;36meval_batch_size\u001b[0m = \u001b[1;33m[1024]\u001b[0m\u001b[1;36m eval_args\u001b[0m: \u001b[1;33m[{'split': {'RS': [0.6, 0.2, 0.2]}, 'fold': 0, 'group_by': 'none', 'order': 'RO', 'mode': 'full'}]\u001b[0m\n",
      "\n",
      "15 Feb 21:36    INFO  Loading model structure and parameters from /home/marta/jku/activity_fair/saved/ml-100k_harm10/MultiVAE-Feb-15-2023_21-36-33.pth\u001b[0m\n",
      "\n",
      "100%|████████████████████| 48/48 [40:41<00:00, 50.87s/trial, best loss: -0.2865]\n",
      "best params:  {'anneal_cap': 1.0, 'latent_dimension': 1000, 'learning_rate': 0.001, 'mlp_hidden_size': '[]', 'total_anneal_steps': 5000.0}\n",
      "best result: \n",
      "{'model': 'MultiVAE', 'best_valid_score': 0.2865, 'valid_score_bigger': True, 'best_valid_result': OrderedDict([('ndcg@10', 0.2865)]), 'test_result': OrderedDict([('ndcg@10', 0.3758)])}\n",
      "CPU times: user 2min 6s, sys: 16.1 s, total: 2min 22s\n",
      "Wall time: 2h 56min\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "BASE_FOLDER = '/home/marta/jku/activity_fair/'\n",
    "\n",
    "CONFIG_FILE = config_dict[MODEL]\n",
    "PARAMS_FILE = params_dict[MODEL]\n",
    "\n",
    "for data_version, data_path in data_path_dict.items():\n",
    "    command = f\"python {BASE_FOLDER}/run_hyper.py \\\n",
    "    --model={MODEL} \\\n",
    "    --data_path={data_path} \\\n",
    "    --dataset={data_version} \\\n",
    "    --config_files={BASE_FOLDER}/config/{CONFIG_FILE}.yaml \\\n",
    "    --params_file={BASE_FOLDER}/config/{PARAMS_FILE}.yaml \\\n",
    "    --checkpoint_dir={BASE_FOLDER}saved/{data_version}\\\n",
    "    --tool=Hyperopt\"\n",
    "    !eval {command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e016b-dd6d-4e9a-ae24-763f9833cf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole",
   "language": "python",
   "name": "recbole"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
